{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\temil\\onedrive\\documents\\codes_and_scripts\\python_envs\\pytorch-tf2-env\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\users\\temil\\onedrive\\documents\\codes_and_scripts\\python_envs\\pytorch-tf2-env\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "c:\\users\\temil\\onedrive\\documents\\codes_and_scripts\\python_envs\\pytorch-tf2-env\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "import os, argparse, torch, gc\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.nn import MSELoss\n",
    "from easydict import EasyDict as edict\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from leo_segmentation.data import Datagenerator, TrainingStats\n",
    "from leo_segmentation.model import LEO, load_model, save_model\n",
    "from leo_segmentation.utils import load_config, check_experiment, get_named_dict\n",
    "from run import train_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num tasks: 7\n",
      "tr_data shape: torch.Size([7, 2, 384, 512, 14]),tr_data_masks shape: torch.Size([7, 2, 384, 512]), val_data shape: torch.Size([7, 5, 384, 512, 14]),val_masks shape: torch.Size([7, 5, 384, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\temil\\OneDrive\\Documents\\Study\\UHildesheim\\Project\\Scripts\\leo-srp-project\\merge_to_dev\\leo_segmentation\\leo_segmentation\\model.py:102: UserWarning: Mixed memory format inputs detected while calling the operator. The operator will output channels_last tensor even if some of the inputs are not in channels_last format. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorIterator.cpp:924.)\n",
      "  channel_zero = inputs * predicted_weights[:, :14, :, :]\n",
      "c:\\users\\temil\\onedrive\\documents\\codes_and_scripts\\python_envs\\pytorch-tf2-env\\lib\\site-packages\\torch\\autograd\\__init__.py:192: UserWarning: Mixed memory format inputs detected while calling the operator. The operator will output contiguous tensor even if some of the inputs are in channels_last format. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorIterator.cpp:918.)\n",
      "  inputs, allow_unused)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-97a701c7ce50>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mleo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeta_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\OneDrive\\Documents\\Study\\UHildesheim\\Project\\Scripts\\leo-srp-project\\merge_to_dev\\leo_segmentation\\run.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mmetadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_batch_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mclass_in_metadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[0mmetatrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_stats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mleo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_stats\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0mmetatrain_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\Study\\UHildesheim\\Project\\Scripts\\leo-srp-project\\merge_to_dev\\leo_segmentation\\leo_segmentation\\model.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[1;34m(self, metadata, train_stats, mode)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m             tr_loss, adapted_seg_weights = self.leo_inner_loop(\\\n\u001b[1;32m--> 192\u001b[1;33m                             data_dict.tr_data, latents, data_dict.tr_data_masks)\n\u001b[0m\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m             \u001b[0mval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinetuning_inner_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtr_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madapted_seg_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\Study\\UHildesheim\\Project\\Scripts\\leo-srp-project\\merge_to_dev\\leo_segmentation\\leo_segmentation\\model.py\u001b[0m in \u001b[0;36mleo_inner_loop\u001b[1;34m(self, inputs, latents, target)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_adaptation_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m             \u001b[0mlatents_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlatents\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m                 \u001b[0mlatents\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0minner_lr\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlatents_grad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\temil\\onedrive\\documents\\codes_and_scripts\\python_envs\\pytorch-tf2-env\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[1;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[0;32m    190\u001b[0m     return Variable._execution_engine.run_backward(\n\u001b[0;32m    191\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 192\u001b[1;33m         inputs, allow_unused)\n\u001b[0m\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "leo, meta_data, classes = train_model(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions on Meta Val / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "leo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = Datagenerator(config, dataset=\"pascal_voc\", data_type=\"meta_val\")\n",
    "val_meta_data = dataloader.get_batch_data()\n",
    "class_in_metadata = val_meta_data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_in_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_class = -1\n",
    "select_sample = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"class\", class_in_metadata[select_class], \"is selected\")\n",
    "batch_data = get_named_dict(val_meta_data, select_class)\n",
    "input_data = batch_data.val_data[select_sample].permute(1, 2, 0)\n",
    "plt.title(\"First three channels of embeddings is visualized\")\n",
    "plt.imshow(input_data.cpu().detach().numpy()[:,:,:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data.val_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latents, kl_loss = leo.forward_encoder(batch_data.tr_data)\n",
    "tr_loss, predicted_weights, _ = leo.forward_decoder(batch_data.tr_data, latents, batch_data.tr_data_masks)\n",
    "val_loss = leo.finetuning_inner_loop(batch_data, tr_loss, predicted_weights)\n",
    "_, _, predictions = leo.forward_decoder(batch_data.val_data, latents, batch_data.val_data_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_sample = 0\n",
    "def plot_batch_mask(batch_data, select_sample):\n",
    "    input_mask = batch_data.val_data_masks[select_sample]\n",
    "    plt.title(\"ground truth mask\")\n",
    "    plt.imshow(input_mask.cpu().detach().numpy(), cmap=\"gray\")\n",
    "    return\n",
    "\n",
    "plot_batch_mask(batch_data, select_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction_mask(pred_mask, select_sample):\n",
    "    plt.title(\"mask prediction\")\n",
    "    plt.imshow(np.argmax(pred_mask[select_sample].cpu().detach().numpy(), 0), cmap=\"gray\")\n",
    "    return\n",
    "\n",
    "plot_prediction_mask(predictions, select_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_iou_per_class(predictions, batch_data.val_data_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-tf2-env",
   "language": "python",
   "name": "pytorch-tf2-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
